{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8c8afb",
   "metadata": {},
   "source": [
    "# Chroma\n",
    "Chroma is a AI native open-source vector database focused on developer productivity and happiness.Chroma is under Apache under 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563c381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a sample vectordb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9caba792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). It helps developers create chains of components, such as prompt templates, memory, LLMs, and agents, to build context-aware, intelligent applications.\\n\\nOne of the core advantages of LangChain is its modularity. Developers can start with basic chains and progressively add more complex functionality such as custom tools, retrieval augmentation using vector stores, or multi-agent collaboration systems.\\n\\nLangChain supports multiple LLM providers such as OpenAI, Anthropic, Cohere, and Hugging Face. It also integrates with various vector stores like FAISS, Pinecone, Weaviate, and Chroma to enable efficient document retrieval and semantic search capabilities.\\n\\nFor data ingestion, LangChain provides several document loaders. These include loaders for plain text, PDFs, CSVs, Notion, GitHub repositories, and even web pages via BeautifulSoup. This makes LangChain an ideal choice for applications such as chatbots, question-answering systems, summarization engines, and autonomous agents.\\n\\nTo process and manage long documents, LangChain includes powerful text splitters like `CharacterTextSplitter`, `RecursiveCharacterTextSplitter`, and `MarkdownHeaderTextSplitter`. These tools break documents into manageable chunks while preserving context.\\n\\nLangChain also provides support for memory modules that enable chat history retention across multiple interactions, allowing LLMs to respond more intelligently. Memory types include ConversationBufferMemory, SummaryMemory, and VectorStoreRetrieverMemory.\\n\\nTo build interactive and autonomous systems, LangChain supports the creation of agentsâ€”entities that decide which tools to call and when, based on natural language instructions. These agents can use tools like search engines, calculators, or even custom APIs to answer questions and perform tasks.\\n\\nOverall, LangChain offers a flexible, extensible, and production-ready framework for building LLM-based applications that can ingest data, reason over it, and provide human-like responses in real time.\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the text file\n",
    "loader=TextLoader(\"speech.txt\")\n",
    "document=loader.load()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c52a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split using RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "splits = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd20887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naidu\\AppData\\Local\\Temp\\ipykernel_12080\\3469805020.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings=OllamaEmbeddings(model=\"gemma:2b\")\n"
     ]
    }
   ],
   "source": [
    "embeddings=OllamaEmbeddings(model=\"gemma:2b\")\n",
    "# Create a Chroma vector store\n",
    "vectordb=Chroma.from_documents(documents=splits,embedding=embeddings,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0bd44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For data ingestion, LangChain provides several document loaders. These include loaders for plain'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query it\n",
    "query = \"For data ingestion, LangChain provides several document loaders. These include loaders for plain text,\"\n",
    "\n",
    "docs=vectordb.similarity_search(query)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98c78974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to db\n",
    "vectordb=Chroma.from_documents(documents=splits,embedding=embeddings,persist_directory=\"./Chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "317492de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For data ingestion, LangChain provides several document loaders. These include loaders for plain\n"
     ]
    }
   ],
   "source": [
    "#load from the disk\n",
    "db2=Chroma(persist_directory=\"./Chroma_db\",embedding_function=embeddings)\n",
    "#query it again\n",
    "docs=db2.similarity_search(query)\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f04ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='9dd76164-43cf-4322-ba24-1a21bc33c0b1', metadata={'source': 'speech.txt'}, page_content='For data ingestion, LangChain provides several document loaders. These include loaders for plain'),\n",
       "  3096.984375),\n",
       " (Document(id='8174e4bd-e1f2-48de-929c-ed3d2f7356d4', metadata={'source': 'speech.txt'}, page_content='For data ingestion, LangChain provides several document loaders. These include loaders for plain'),\n",
       "  3096.984375),\n",
       " (Document(id='27703f0d-85fe-472f-a598-3f53f8ce05c6', metadata={'source': 'speech.txt'}, page_content='To process and manage long documents, LangChain includes powerful text splitters like'),\n",
       "  4377.20458984375),\n",
       " (Document(id='2fc72cd8-0b7a-47bd-8bde-018603c72e8c', metadata={'source': 'speech.txt'}, page_content='To process and manage long documents, LangChain includes powerful text splitters like'),\n",
       "  4377.20458984375)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## similarity searfch score\n",
    "docs=vectordb.similarity_search_with_score(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eddce64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For data ingestion, LangChain provides several document loaders. These include loaders for plain'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retriver option\n",
    "retriver=vectordb.as_retriever()\n",
    "retriver.invoke(query)[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
