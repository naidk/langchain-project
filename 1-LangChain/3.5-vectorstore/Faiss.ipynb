{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575601df",
   "metadata": {},
   "source": [
    "Facebook AI Similarity Search(Faiss) is a library for efficient for similarity search and clustering of dense vectors.It contains algorithms that search in sets of vector of any size,up to ones that possibly do not fit in RAM.It also contain supporting code for evaluation and parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4acf4d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 278, which is longer than the specified 100\n",
      "Created a chunk of size 250, which is longer than the specified 100\n",
      "Created a chunk of size 256, which is longer than the specified 100\n",
      "Created a chunk of size 327, which is longer than the specified 100\n",
      "Created a chunk of size 255, which is longer than the specified 100\n",
      "Created a chunk of size 254, which is longer than the specified 100\n",
      "Created a chunk of size 297, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"speech.txt\")\n",
    "documnets=loader.load()\n",
    "text_splitter=CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "docs=text_splitter.split_documents(documnets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd40524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). It helps developers create chains of components, such as prompt templates, memory, LLMs, and agents, to build context-aware, intelligent applications.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='One of the core advantages of LangChain is its modularity. Developers can start with basic chains and progressively add more complex functionality such as custom tools, retrieval augmentation using vector stores, or multi-agent collaboration systems.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='LangChain supports multiple LLM providers such as OpenAI, Anthropic, Cohere, and Hugging Face. It also integrates with various vector stores like FAISS, Pinecone, Weaviate, and Chroma to enable efficient document retrieval and semantic search capabilities.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='For data ingestion, LangChain provides several document loaders. These include loaders for plain text, PDFs, CSVs, Notion, GitHub repositories, and even web pages via BeautifulSoup. This makes LangChain an ideal choice for applications such as chatbots, question-answering systems, summarization engines, and autonomous agents.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='To process and manage long documents, LangChain includes powerful text splitters like `CharacterTextSplitter`, `RecursiveCharacterTextSplitter`, and `MarkdownHeaderTextSplitter`. These tools break documents into manageable chunks while preserving context.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='LangChain also provides support for memory modules that enable chat history retention across multiple interactions, allowing LLMs to respond more intelligently. Memory types include ConversationBufferMemory, SummaryMemory, and VectorStoreRetrieverMemory.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='To build interactive and autonomous systems, LangChain supports the creation of agentsâ€”entities that decide which tools to call and when, based on natural language instructions. These agents can use tools like search engines, calculators, or even custom APIs to answer questions and perform tasks.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Overall, LangChain offers a flexible, extensible, and production-ready framework for building LLM-based applications that can ingest data, reason over it, and provide human-like responses in real time.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d9a210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naidu\\AppData\\Local\\Temp\\ipykernel_23860\\3773654592.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings=OllamaEmbeddings(model=\"gemma:2b\")\n"
     ]
    }
   ],
   "source": [
    "embeddings=OllamaEmbeddings(model=\"gemma:2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e43ebd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1e8dd0ff820>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db=FAISS.from_documents(docs,embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb5d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quering\n",
    "query = \"For data ingestion, LangChain provides several document loaders. These include loaders for plain text,\"\n",
    "results = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d434bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To process and manage long documents, LangChain includes powerful text splitters like `CharacterTextSplitter`, `RecursiveCharacterTextSplitter`, and `MarkdownHeaderTextSplitter`. These tools break documents into manageable chunks while preserving context.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bfdb31",
   "metadata": {},
   "source": [
    "## Retriver\n",
    "\n",
    "we can aslo convert out databasse vector class into a vectorclass. This allow us it easily use it in other Langchain  methods ,which largely work with retrivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e70cdf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To process and manage long documents, LangChain includes powerful text splitters like `CharacterTextSplitter`, `RecursiveCharacterTextSplitter`, and `MarkdownHeaderTextSplitter`. These tools break documents into manageable chunks while preserving context.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver=db.as_retriever()\n",
    "docs=retriver.invoke(query)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075941c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b466e0c",
   "metadata": {},
   "source": [
    "### Similarity Search with Scores\n",
    "There are some FAISS specific methods.one of them is similarity_search_with_score ,which allow you to return not only the documnet but also the distance score of the query to them.The returned score is L2 distance.Therefore ,a lower score is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d5c53b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='084d39a1-e530-4f40-b0ed-6caccc0009fc', metadata={'source': 'speech.txt'}, page_content='To process and manage long documents, LangChain includes powerful text splitters like `CharacterTextSplitter`, `RecursiveCharacterTextSplitter`, and `MarkdownHeaderTextSplitter`. These tools break documents into manageable chunks while preserving context.'),\n",
       "  4932.908),\n",
       " (Document(id='067cb4b2-fa32-469d-9c04-ea82b0c5de3a', metadata={'source': 'speech.txt'}, page_content='LangChain supports multiple LLM providers such as OpenAI, Anthropic, Cohere, and Hugging Face. It also integrates with various vector stores like FAISS, Pinecone, Weaviate, and Chroma to enable efficient document retrieval and semantic search capabilities.'),\n",
       "  5288.799),\n",
       " (Document(id='e780117b-09e4-49b4-959b-d3cd323f09a5', metadata={'source': 'speech.txt'}, page_content='LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). It helps developers create chains of components, such as prompt templates, memory, LLMs, and agents, to build context-aware, intelligent applications.'),\n",
       "  5322.7163),\n",
       " (Document(id='c6535980-96d8-4f5f-81b1-2d53bb351d36', metadata={'source': 'speech.txt'}, page_content='For data ingestion, LangChain provides several document loaders. These include loaders for plain text, PDFs, CSVs, Notion, GitHub repositories, and even web pages via BeautifulSoup. This makes LangChain an ideal choice for applications such as chatbots, question-answering systems, summarization engines, and autonomous agents.'),\n",
       "  5323.585)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_scores=db.similarity_search_with_score(query)\n",
    "docs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e7547b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emebeding_vector=embeddings.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6aba0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='084d39a1-e530-4f40-b0ed-6caccc0009fc', metadata={'source': 'speech.txt'}, page_content='To process and manage long documents, LangChain includes powerful text splitters like `CharacterTextSplitter`, `RecursiveCharacterTextSplitter`, and `MarkdownHeaderTextSplitter`. These tools break documents into manageable chunks while preserving context.'),\n",
       " Document(id='067cb4b2-fa32-469d-9c04-ea82b0c5de3a', metadata={'source': 'speech.txt'}, page_content='LangChain supports multiple LLM providers such as OpenAI, Anthropic, Cohere, and Hugging Face. It also integrates with various vector stores like FAISS, Pinecone, Weaviate, and Chroma to enable efficient document retrieval and semantic search capabilities.'),\n",
       " Document(id='e780117b-09e4-49b4-959b-d3cd323f09a5', metadata={'source': 'speech.txt'}, page_content='LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). It helps developers create chains of components, such as prompt templates, memory, LLMs, and agents, to build context-aware, intelligent applications.'),\n",
       " Document(id='c6535980-96d8-4f5f-81b1-2d53bb351d36', metadata={'source': 'speech.txt'}, page_content='For data ingestion, LangChain provides several document loaders. These include loaders for plain text, PDFs, CSVs, Notion, GitHub repositories, and even web pages via BeautifulSoup. This makes LangChain an ideal choice for applications such as chatbots, question-answering systems, summarization engines, and autonomous agents.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_scores=db.similarity_search_by_vector(emebeding_vector)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "528e664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving and loading the vector store\n",
    "db.save_local(\"faiss_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71eb9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"faiss_store\", embeddings,allow_dangerous_deserialization=True)\n",
    "docs = new_db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed470f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='084d39a1-e530-4f40-b0ed-6caccc0009fc', metadata={'source': 'speech.txt'}, page_content='To process and manage long documents, LangChain includes powerful text splitters like `CharacterTextSplitter`, `RecursiveCharacterTextSplitter`, and `MarkdownHeaderTextSplitter`. These tools break documents into manageable chunks while preserving context.'),\n",
       " Document(id='067cb4b2-fa32-469d-9c04-ea82b0c5de3a', metadata={'source': 'speech.txt'}, page_content='LangChain supports multiple LLM providers such as OpenAI, Anthropic, Cohere, and Hugging Face. It also integrates with various vector stores like FAISS, Pinecone, Weaviate, and Chroma to enable efficient document retrieval and semantic search capabilities.'),\n",
       " Document(id='e780117b-09e4-49b4-959b-d3cd323f09a5', metadata={'source': 'speech.txt'}, page_content='LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). It helps developers create chains of components, such as prompt templates, memory, LLMs, and agents, to build context-aware, intelligent applications.'),\n",
       " Document(id='c6535980-96d8-4f5f-81b1-2d53bb351d36', metadata={'source': 'speech.txt'}, page_content='For data ingestion, LangChain provides several document loaders. These include loaders for plain text, PDFs, CSVs, Notion, GitHub repositories, and even web pages via BeautifulSoup. This makes LangChain an ideal choice for applications such as chatbots, question-answering systems, summarization engines, and autonomous agents.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
