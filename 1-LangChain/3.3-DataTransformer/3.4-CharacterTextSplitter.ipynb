{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b8ee82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). It helps developers create chains of components, such as prompt templates, memory, LLMs, and agents, to build context-aware, intelligent applications.\\n\\nOne of the core advantages of LangChain is its modularity. Developers can start with basic chains and progressively add more complex functionality such as custom tools, retrieval augmentation using vector stores, or multi-agent collaboration systems.\\n\\nLangChain supports multiple LLM providers such as OpenAI, Anthropic, Cohere, and Hugging Face. It also integrates with various vector stores like FAISS, Pinecone, Weaviate, and Chroma to enable efficient document retrieval and semantic search capabilities.\\n\\nFor data ingestion, LangChain provides several document loaders. These include loaders for plain text, PDFs, CSVs, Notion, GitHub repositories, and even web pages via BeautifulSoup. This makes LangChain an ideal choice for applications such as chatbots, question-answering systems, summarization engines, and autonomous agents.\\n\\nTo process and manage long documents, LangChain includes powerful text splitters like `CharacterTextSplitter`, `RecursiveCharacterTextSplitter`, and `MarkdownHeaderTextSplitter`. These tools break documents into manageable chunks while preserving context.\\n\\nLangChain also provides support for memory modules that enable chat history retention across multiple interactions, allowing LLMs to respond more intelligently. Memory types include ConversationBufferMemory, SummaryMemory, and VectorStoreRetrieverMemory.\\n\\nTo build interactive and autonomous systems, LangChain supports the creation of agentsâ€”entities that decide which tools to call and when, based on natural language instructions. These agents can use tools like search engines, calculators, or even custom APIs to answer questions and perform tasks.\\n\\nOverall, LangChain offers a flexible, extensible, and production-ready framework for building LLM-based applications that can ingest data, reason over it, and provide human-like responses in real time.\\n')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text loaders\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader=TextLoader(\"speech.txt\")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92c9b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 278, which is longer than the specified 100\n",
      "Created a chunk of size 250, which is longer than the specified 100\n",
      "Created a chunk of size 256, which is longer than the specified 100\n",
      "Created a chunk of size 327, which is longer than the specified 100\n",
      "Created a chunk of size 255, which is longer than the specified 100\n",
      "Created a chunk of size 254, which is longer than the specified 100\n",
      "Created a chunk of size 297, which is longer than the specified 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'speech.txt'}, page_content='LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). It helps developers create chains of components, such as prompt templates, memory, LLMs, and agents, to build context-aware, intelligent applications.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Split the document using CharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter       \n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",        # split by paragraph\n",
    "    chunk_size=100,          # each chunk is ~100 characters\n",
    "    chunk_overlap=50         # 50 characters of overlap for context\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a656f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 278, which is longer than the specified 100\n",
      "Created a chunk of size 250, which is longer than the specified 100\n",
      "Created a chunk of size 256, which is longer than the specified 100\n",
      "Created a chunk of size 327, which is longer than the specified 100\n",
      "Created a chunk of size 255, which is longer than the specified 100\n",
      "Created a chunk of size 254, which is longer than the specified 100\n",
      "Created a chunk of size 297, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). It helps developers create chains of components, such as prompt templates, memory, LLMs, and agents, to build context-aware, intelligent applications.'\n",
      "page_content='One of the core advantages of LangChain is its modularity. Developers can start with basic chains and progressively add more complex functionality such as custom tools, retrieval augmentation using vector stores, or multi-agent collaboration systems.'\n"
     ]
    }
   ],
   "source": [
    "speech = \"\"\n",
    "with open(\"speech.txt\",\"r\") as file:\n",
    "    speech = file.read()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "text=text_splitter.create_documents([speech])\n",
    "print(text[0])\n",
    "print(text[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
